{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dcd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from sparc.feature_extract.extract_open_images import OpenImagesDataset\n",
    "\n",
    "from sparc.post_analysis import HDF5AnalysisResultsDataset\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e69578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading caption data from /home/ubuntu/Projects/OpenImages/captions/test/simplified_open_images_test_localized_narratives.json...\n",
      "Loading label data...\n",
      "Total number of classes: 601\n",
      "Loading annotations from /home/ubuntu/Projects/OpenImages/labels/test-annotations-human-imagelabels-boxable.csv...\n",
      "Loaded labels for 112194 images\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "dataset = OpenImagesDataset('/home/ubuntu/Projects/OpenImages/', 'test')\n",
    "with open('/home/ubuntu/Projects/OpenImages/bbox_labels_600_hierarchy.json', 'r') as f:\n",
    "    taxonomy_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fba85f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_class = {value:key for key,value in dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134c8e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 126020/126020 [00:04<00:00, 27296.08it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "sample_indices = []\n",
    "for idx in tqdm(range(len(dataset))):\n",
    "    image_id, caption_idx = dataset.samples[idx]\n",
    "    if image_id in dataset.image_to_label_tensor:\n",
    "        labels_tensor = dataset.image_to_label_tensor[image_id]\n",
    "        labels.append(csr_matrix(labels_tensor))\n",
    "        sample_indices.append(idx)\n",
    "sample_indices = np.array(sample_indices)\n",
    "label_matrix_sparse = vstack(labels).tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2412d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results_global_cross = HDF5AnalysisResultsDataset('../../final_results/msae_open_global_with_cross/analysis_cache_val.h5', 256)\n",
    "analysis_results_global_no_cross = HDF5AnalysisResultsDataset('../../final_results/msae_open_global_no_cross/analysis_cache_val.h5', 256)\n",
    "analysis_results_local_cross = HDF5AnalysisResultsDataset('../../final_results/msae_open_local_with_cross/analysis_cache_val.h5', 256)\n",
    "analysis_results_local_no_cross = HDF5AnalysisResultsDataset('../../final_results/msae_open_local_no_cross/analysis_cache_val.h5', 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28594dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_file = os.path.join(dataset.labels_dir, 'oidv7-class-descriptions-boxable.csv')\n",
    "class_df = pd.read_csv(class_file)\n",
    "label_to_class = {row['LabelName']: row['DisplayName'] \n",
    "                      for _, row in class_df.iterrows()}\n",
    "class_to_label = {v: k for k, v in label_to_class.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63108fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def build_parent_depth_maps(node):\n",
    "    parent_map = {}\n",
    "    depth_map  = {}\n",
    "    def dfs(n, parent=None, depth=0):\n",
    "        code = n['LabelName']\n",
    "        # only override if this occurrence is deeper than any seen so far (it happens for Teddy Bear for exmaple)\n",
    "        if code not in depth_map or depth > depth_map[code]:\n",
    "            parent_map[code] = parent\n",
    "            depth_map[code]  = depth\n",
    "        for child in n.get('Subcategory', []):\n",
    "            dfs(child, code, depth+1)\n",
    "    dfs(node, None, 0)\n",
    "    return parent_map, depth_map\n",
    "\n",
    "\n",
    "_parent_map, _depth_map = build_parent_depth_maps(taxonomy_json)\n",
    "_max_depth = max(_depth_map.values())\n",
    "\n",
    "# ——————————————————————————————————————————————\n",
    "# 2) Helper to build counts and activation‐counts\n",
    "# ——————————————————————————————————————————————\n",
    "def _build_counts_matrix(analysis_results, topk=None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      counts_arr:        np.array shape (L, S, C)\n",
    "      activation_counts: np.array shape (L, S)\n",
    "      streams:           list of stream names\n",
    "\n",
    "    If topk is None, we include *all* nonzero activations for each latent.\n",
    "    If topk is an integer, we take only the top `topk` activated samples.\n",
    "    \"\"\"\n",
    "    all_indices    = analysis_results.get_all_original_dataset_indices()\n",
    "    idx_to_row     = {orig: r for r, orig in enumerate(all_indices)}\n",
    "    sample_rows    = np.array([idx_to_row[i] for i in sample_indices])\n",
    "\n",
    "    total_rows, num_classes = label_matrix_sparse.shape\n",
    "    if total_rows == len(all_indices):\n",
    "        labels_sub = label_matrix_sparse.tocsr()[sample_rows]\n",
    "    elif total_rows == len(sample_indices):\n",
    "        labels_sub = label_matrix_sparse.tocsr()\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"label_matrix_sparse has {total_rows} rows; expected \"\n",
    "            f\"{len(all_indices)} or {len(sample_indices)}\"\n",
    "        )\n",
    "\n",
    "    streams = analysis_results.streams\n",
    "    latent_mats = {\n",
    "        s: analysis_results\n",
    "             .get_all_features_for_stream(s, 'latents', return_sparse=True)\n",
    "             [sample_rows]\n",
    "             .tocsc()\n",
    "        for s in streams\n",
    "    }\n",
    "\n",
    "    L = latent_mats[streams[0]].shape[1]\n",
    "    S = len(streams)\n",
    "    C = num_classes\n",
    "\n",
    "    counts_arr        = np.zeros((L, S, C), dtype=int)\n",
    "    activation_counts = np.zeros((L, S),   dtype=int)\n",
    "\n",
    "    for s_idx, s in enumerate(streams):\n",
    "        mat = latent_mats[s]\n",
    "        for l in range(L):\n",
    "            col = mat.getcol(l)\n",
    "            nnz = col.nnz\n",
    "            activation_counts[l, s_idx] = nnz\n",
    "            if nnz == 0:\n",
    "                continue\n",
    "\n",
    "            # choose which rows to include\n",
    "            if topk is None or topk >= nnz:\n",
    "                # use all nonzero activations\n",
    "                rows = col.indices\n",
    "            else:\n",
    "                # pick only the top `topk` activations\n",
    "                k    = int(topk)\n",
    "                # argpartition gives us the indices of the k largest values\n",
    "                topk_idx = np.argpartition(-col.data, k-1)[:k]\n",
    "                rows     = col.indices[topk_idx]\n",
    "\n",
    "            # sum up class counts over the selected rows\n",
    "            counts_arr[l, s_idx, :] = labels_sub[rows].sum(axis=0).A1\n",
    "\n",
    "    return counts_arr, activation_counts, streams\n",
    "\n",
    "# list of all \"/m/...\" codes in the same order as the label matrix columns\n",
    "_label_codes = list(dataset.label_to_class.keys())\n",
    "root_code = taxonomy_json[\"LabelName\"]   \n",
    "\n",
    "# ——————————————————————————————————————————————\n",
    "# 3) Ancestor‐collapsed Jaccard at chosen depth\n",
    "# ——————————————————————————————————————————————\n",
    "def compute_jaccard_from_counts(counts_arr, activation_counts, collapse_depth):\n",
    "    # 1) validate\n",
    "    if not isinstance(collapse_depth, int):\n",
    "        raise TypeError(f\"collapse_depth must be int, got {type(collapse_depth)}\")\n",
    "    if collapse_depth < 0 or collapse_depth > _max_depth:\n",
    "        raise ValueError(f\"collapse_depth must be in [0, {_max_depth}]\")\n",
    "\n",
    "    L, S, C = counts_arr.shape\n",
    "\n",
    "    # 2) build bucket_codes\n",
    "    if collapse_depth == 0:\n",
    "        # everything merges into the single root bucket\n",
    "        bucket_codes = [root_code] * C\n",
    "    else:\n",
    "        def lift(code):\n",
    "            d = _depth_map[code]\n",
    "            while d > collapse_depth:\n",
    "                code = _parent_map[code]\n",
    "                d    = _depth_map[code]\n",
    "            return code\n",
    "        bucket_codes = [lift(c) for c in _label_codes]\n",
    "\n",
    "    unique_buckets = sorted(set(bucket_codes))\n",
    "    b2i = {bc: i for i, bc in enumerate(unique_buckets)}\n",
    "    B = len(unique_buckets)\n",
    "\n",
    "    # 3) collapse counts\n",
    "    collapsed = np.zeros((L, S, B), dtype=int)\n",
    "    for ci, bc in enumerate(bucket_codes):\n",
    "        bi = b2i[bc]\n",
    "        collapsed[:, :, bi] += counts_arr[:, :, ci]\n",
    "\n",
    "    # 4) compute ancestor‐collapsed Jaccard\n",
    "    j_scores = np.zeros(L, dtype=float)\n",
    "    for l in range(L):\n",
    "        active = [s for s in range(S) if activation_counts[l, s] > 0]\n",
    "        if len(active) < 2:\n",
    "            continue\n",
    "        total = 0.0\n",
    "        for i, j in combinations(active, 2):\n",
    "            A = collapsed[l, i]\n",
    "            Bv = collapsed[l, j]\n",
    "            num = np.minimum(A, Bv).sum()\n",
    "            den = np.maximum(A, Bv).sum()\n",
    "            total += (num / den) if den > 0 else 0.0\n",
    "        j_scores[l] = total / (len(active)*(len(active)-1)/2)\n",
    "    return j_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706c6cbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Case:   0%|                                               | 0/4 [00:00<?, ?it/s]\n",
      "Depth [global_cross]:   0%|                               | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Depth [global_cross]:  33%|███████▋               | 2/6 [00:00<00:00, 10.34it/s]\u001b[A\n",
      "Depth [global_cross]:  67%|███████████████▎       | 4/6 [00:00<00:00,  7.13it/s]\u001b[A\n",
      "Depth [global_cross]:  83%|███████████████████▏   | 5/6 [00:00<00:00,  6.26it/s]\u001b[A\n",
      "Depth [global_cross]: 100%|███████████████████████| 6/6 [00:00<00:00,  5.75it/s]\u001b[A\n",
      "Case:  25%|█████████▊                             | 1/4 [00:08<00:25,  8.47s/it]\u001b[A\n",
      "Depth [global_no_cross]:   0%|                            | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Depth [global_no_cross]:  33%|██████▋             | 2/6 [00:00<00:00,  9.72it/s]\u001b[A\n",
      "Depth [global_no_cross]:  50%|██████████          | 3/6 [00:00<00:00,  7.36it/s]\u001b[A\n",
      "Depth [global_no_cross]:  67%|█████████████▎      | 4/6 [00:00<00:00,  6.06it/s]\u001b[A\n",
      "Depth [global_no_cross]:  83%|████████████████▋   | 5/6 [00:00<00:00,  5.44it/s]\u001b[A\n",
      "Depth [global_no_cross]: 100%|████████████████████| 6/6 [00:01<00:00,  5.11it/s]\u001b[A\n",
      "Case:  50%|███████████████████▌                   | 2/4 [00:16<00:16,  8.05s/it]\u001b[A\n",
      "Depth [local_cross]:   0%|                                | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Depth [local_cross]:  33%|████████                | 2/6 [00:00<00:00, 11.97it/s]\u001b[A\n",
      "Depth [local_cross]:  67%|████████████████        | 4/6 [00:00<00:00,  7.28it/s]\u001b[A\n",
      "Depth [local_cross]:  83%|████████████████████    | 5/6 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "Depth [local_cross]: 100%|████████████████████████| 6/6 [00:00<00:00,  6.01it/s]\u001b[A\n",
      "Case:  75%|█████████████████████████████▎         | 3/4 [00:24<00:08,  8.20s/it]\u001b[A\n",
      "Depth [local_no_cross]:   0%|                             | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      "Depth [local_no_cross]:  33%|███████              | 2/6 [00:00<00:00, 10.16it/s]\u001b[A\n",
      "Depth [local_no_cross]:  67%|██████████████       | 4/6 [00:00<00:00,  6.48it/s]\u001b[A\n",
      "Depth [local_no_cross]:  83%|█████████████████▌   | 5/6 [00:00<00:00,  5.80it/s]\u001b[A\n",
      "Depth [local_no_cross]: 100%|█████████████████████| 6/6 [00:01<00:00,  5.40it/s]\u001b[A\n",
      "Case: 100%|███████████████████████████████████████| 4/4 [00:33<00:00,  8.35s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "# Define your four analysis_results cases\n",
    "cases = {\n",
    "    'global_cross':    analysis_results_global_cross,\n",
    "    'global_no_cross': analysis_results_global_no_cross,\n",
    "    'local_cross':     analysis_results_local_cross,\n",
    "    'local_no_cross':  analysis_results_local_no_cross,\n",
    "}\n",
    "\n",
    "# Initialize results structure: for each metric, a dict mapping depth→case→scores\n",
    "results = {\n",
    "    'jaccard': {depth: {} for depth in range(_max_depth + 1)},\n",
    "    'dice':    {depth: {} for depth in range(_max_depth + 1)},\n",
    "}\n",
    "\n",
    "# Outer loop over the four cases; _build_counts_matrix runs once per case\n",
    "for case_name, ar in tqdm(cases.items(), desc=\"Case\", total=len(cases)):\n",
    "    counts_arr, activation_counts, streams = _build_counts_matrix(ar)\n",
    "\n",
    "    # Inner loop over all depths; compute both metrics at each depth\n",
    "    for depth in tqdm(range(_max_depth + 1),\n",
    "                      desc=f\"Depth [{case_name}]\",\n",
    "                      leave=False):\n",
    "        # Compute Jaccard from the precomputed counts\n",
    "        j_scores = compute_jaccard_from_counts( counts_arr,\n",
    "                                                activation_counts,\n",
    "                                                depth)\n",
    "        results['jaccard'][depth][case_name] = j_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7878974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== JACCARD SUMMARY ===\n",
      " depth= 0 | global_cross: μ=0.8118 | global_no_cross: μ=0.8054 | local_cross: μ=0.3238 | local_no_cross: μ=0.3458\n",
      " depth= 1 | global_cross: μ=0.8056 | global_no_cross: μ=0.7633 | local_cross: μ=0.2866 | local_no_cross: μ=0.2031\n",
      " depth= 2 | global_cross: μ=0.8032 | global_no_cross: μ=0.7451 | local_cross: μ=0.2706 | local_no_cross: μ=0.1783\n",
      " depth= 3 | global_cross: μ=0.8020 | global_no_cross: μ=0.7359 | local_cross: μ=0.2615 | local_no_cross: μ=0.1666\n",
      " depth= 4 | global_cross: μ=0.8018 | global_no_cross: μ=0.7344 | local_cross: μ=0.2600 | local_no_cross: μ=0.1652\n",
      " depth= 5 | global_cross: μ=0.8018 | global_no_cross: μ=0.7344 | local_cross: μ=0.2599 | local_no_cross: μ=0.1651\n"
     ]
    }
   ],
   "source": [
    "metric = 'jaccard'\n",
    "print(f\"\\n=== {metric.upper()} SUMMARY ===\")\n",
    "for depth, case_dict in results[metric].items():\n",
    "    stats = []\n",
    "    for case_name in cases:\n",
    "        scores = case_dict.get(case_name)\n",
    "        if scores is not None:\n",
    "            stats.append(f\"{case_name}: μ={scores.mean():.4f}\")\n",
    "    print(f\" depth={depth:2d} | \" + \" | \".join(stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907d7fa",
   "metadata": {},
   "source": [
    "# Dead latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6fbbdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing matrices: 100%|██████████████████████| 4/4 [00:29<00:00,  7.32s/it]\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Precompute all the expensive matrix operations\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Precomputing matrices...\")\n",
    "precomputed_data = {}\n",
    "for case_name, ar in tqdm(cases.items(), desc=\"Precomputing matrices\", total=len(cases)):\n",
    "    counts_all, activation_counts_all, streams = _build_counts_matrix(ar, topk=None)\n",
    "    \n",
    "    precomputed_data[case_name] = {\n",
    "        'counts_all': counts_all,\n",
    "        'activation_counts_all': activation_counts_all,\n",
    "        'streams': streams,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd9950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_cross: 6912 all-alive, 1280 all-dead, 0 mixed, 8192 total\n",
      "global_no_cross: 8044 all-alive, 131 all-dead, 17 mixed, 8192 total\n",
      "local_cross: 3575 all-alive, 0 all-dead, 4617 mixed, 8192 total\n",
      "local_no_cross: 7019 all-alive, 0 all-dead, 1173 mixed, 8192 total\n"
     ]
    }
   ],
   "source": [
    "# Check patterns across all cases\n",
    "case_patterns = {}\n",
    "for case_name in precomputed_data.keys():\n",
    "    counts_all = precomputed_data[case_name]['counts_all']\n",
    "    \n",
    "    all_alive_list = []\n",
    "    all_dead_list = []\n",
    "    mixed_list = []\n",
    "    \n",
    "    for i in range(len(counts_all)):\n",
    "        stream_alive = (counts_all[i].sum(axis=1) > 0)  # which streams are alive\n",
    "        num_alive = stream_alive.sum()\n",
    "        \n",
    "        if num_alive == 3:\n",
    "            all_alive_list.append(True)\n",
    "            all_dead_list.append(False)\n",
    "            mixed_list.append(False)\n",
    "        elif num_alive == 0:\n",
    "            all_alive_list.append(False)\n",
    "            all_dead_list.append(True)\n",
    "            mixed_list.append(False)\n",
    "        else:  # 1 or 2 streams alive\n",
    "            all_alive_list.append(False)\n",
    "            all_dead_list.append(False)\n",
    "            mixed_list.append(True)\n",
    "    \n",
    "    case_patterns[case_name] = {\n",
    "        'num_all_alive': sum(all_alive_list),\n",
    "        'num_all_dead': sum(all_dead_list),\n",
    "        'num_mixed': sum(mixed_list),\n",
    "        'total_latents': len(all_alive_list)\n",
    "    }\n",
    "\n",
    "# Summary\n",
    "for case_name, stats in case_patterns.items():\n",
    "    print(f\"{case_name}: {stats['num_all_alive']} all-alive, {stats['num_all_dead']} all-dead, {stats['num_mixed']} mixed, {stats['total_latents']} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7541cfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPREHENSIVE NEURON ACTIVATION PATTERN ANALYSIS\n",
      "Goal: Complete breakdown of neuron activation patterns across all streams\n",
      "======================================================================\n",
      "\n",
      "GLOBAL_CROSS (8192 total neurons)\n",
      "──────────────────────────────────────────────────\n",
      "OVERALL ACTIVATION PATTERNS:\n",
      "  All dead (0/3):          1280 ( 15.6%)\n",
      "  All alive (3/3):         6912 ( 84.4%)\n",
      "  Mixed (1/3):                0 (  0.0%)\n",
      "  Mixed (2/3):                0 (  0.0%)\n",
      "\n",
      "STREAM-SPECIFIC DEAD COUNTS:\n",
      "  CLIP-img    : 1280 dead ( 15.6%)\n",
      "  CLIP-txt    : 1280 dead ( 15.6%)\n",
      "  DINO        : 1280 dead ( 15.6%)\n",
      "\n",
      "GLOBAL_NO_CROSS (8192 total neurons)\n",
      "──────────────────────────────────────────────────\n",
      "OVERALL ACTIVATION PATTERNS:\n",
      "  All dead (0/3):           131 (  1.6%)\n",
      "  All alive (3/3):         8044 ( 98.2%)\n",
      "  Mixed (1/3):                2 (  0.0%)\n",
      "  Mixed (2/3):               15 (  0.2%)\n",
      "\n",
      "STREAM-SPECIFIC DEAD COUNTS:\n",
      "  CLIP-img    :  135 dead (  1.6%)\n",
      "  CLIP-txt    :  144 dead (  1.8%)\n",
      "  DINO        :  133 dead (  1.6%)\n",
      "\n",
      "1/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img only:             0 (  0.0%)\n",
      "  CLIP-txt only:             0 (  0.0%)\n",
      "  DINO only:                 2 (100.0%)\n",
      "\n",
      "2/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img + CLIP-txt:       2 ( 13.3%)\n",
      "  CLIP-img + DINO:          11 ( 73.3%)\n",
      "  CLIP-txt + DINO:           2 ( 13.3%)\n",
      "\n",
      "LOCAL_CROSS (8192 total neurons)\n",
      "──────────────────────────────────────────────────\n",
      "OVERALL ACTIVATION PATTERNS:\n",
      "  All dead (0/3):             0 (  0.0%)\n",
      "  All alive (3/3):         3575 ( 43.6%)\n",
      "  Mixed (1/3):              622 (  7.6%)\n",
      "  Mixed (2/3):             3995 ( 48.8%)\n",
      "\n",
      "STREAM-SPECIFIC DEAD COUNTS:\n",
      "  CLIP-img    : 1355 dead ( 16.5%)\n",
      "  CLIP-txt    : 3688 dead ( 45.0%)\n",
      "  DINO        :  196 dead (  2.4%)\n",
      "\n",
      "1/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img only:            25 (  4.0%)\n",
      "  CLIP-txt only:            67 ( 10.8%)\n",
      "  DINO only:               530 ( 85.2%)\n",
      "\n",
      "2/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img + CLIP-txt:     104 (  2.6%)\n",
      "  CLIP-img + DINO:         3133 ( 78.4%)\n",
      "  CLIP-txt + DINO:         758 ( 19.0%)\n",
      "\n",
      "LOCAL_NO_CROSS (8192 total neurons)\n",
      "──────────────────────────────────────────────────\n",
      "OVERALL ACTIVATION PATTERNS:\n",
      "  All dead (0/3):             0 (  0.0%)\n",
      "  All alive (3/3):         7019 ( 85.7%)\n",
      "  Mixed (1/3):                2 (  0.0%)\n",
      "  Mixed (2/3):             1171 ( 14.3%)\n",
      "\n",
      "STREAM-SPECIFIC DEAD COUNTS:\n",
      "  CLIP-img    :   21 dead (  0.3%)\n",
      "  CLIP-txt    : 1154 dead ( 14.1%)\n",
      "  DINO        :    0 dead (  0.0%)\n",
      "\n",
      "1/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img only:             0 (  0.0%)\n",
      "  CLIP-txt only:             0 (  0.0%)\n",
      "  DINO only:                 2 (100.0%)\n",
      "\n",
      "2/3 PATTERN BREAKDOWN:\n",
      "  CLIP-img + CLIP-txt:       0 (  0.0%)\n",
      "  CLIP-img + DINO:         1152 ( 98.4%)\n",
      "  CLIP-txt + DINO:          19 (  1.6%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Alignment and Dead Neuron Analysis\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPREHENSIVE NEURON ACTIVATION PATTERN ANALYSIS\")\n",
    "print(\"Goal: Complete breakdown of neuron activation patterns across all streams\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for case_name, data in precomputed_data.items():\n",
    "    counts_all = data['counts_all']\n",
    "    stream_names = ['CLIP-img', 'CLIP-txt', 'DINO']\n",
    "    \n",
    "    # Count all patterns\n",
    "    exactly_0_alive = 0\n",
    "    exactly_1_alive = 0\n",
    "    exactly_2_alive = 0\n",
    "    exactly_3_alive = 0\n",
    "    \n",
    "    # Stream-specific dead counts\n",
    "    stream_dead_counts = []\n",
    "    for stream_idx in range(3):\n",
    "        dead_in_stream = (counts_all[:, stream_idx, :].sum(axis=1) == 0).sum()\n",
    "        stream_dead_counts.append(dead_in_stream)\n",
    "    \n",
    "    # 1-out-of-3 patterns\n",
    "    pattern_ci_only = 0   # Only CLIP-img alive\n",
    "    pattern_ct_only = 0   # Only CLIP-txt alive  \n",
    "    pattern_d_only = 0    # Only DINO alive\n",
    "    \n",
    "    # 2-out-of-3 patterns\n",
    "    pattern_ci_ct = 0     # CLIP-img + CLIP-txt alive, DINO dead\n",
    "    pattern_ci_d = 0      # CLIP-img + DINO alive, CLIP-txt dead  \n",
    "    pattern_ct_d = 0      # CLIP-txt + DINO alive, CLIP-img dead\n",
    "\n",
    "    for i in range(len(counts_all)):\n",
    "        stream_alive = (counts_all[i].sum(axis=1) > 0)\n",
    "        num_alive = stream_alive.sum()\n",
    "        \n",
    "        if num_alive == 0:\n",
    "            exactly_0_alive += 1\n",
    "        elif num_alive == 1:\n",
    "            exactly_1_alive += 1\n",
    "            if stream_alive[0] and not stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ci_only += 1\n",
    "            elif not stream_alive[0] and stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ct_only += 1\n",
    "            elif not stream_alive[0] and not stream_alive[1] and stream_alive[2]:\n",
    "                pattern_d_only += 1\n",
    "        elif num_alive == 2:\n",
    "            exactly_2_alive += 1\n",
    "            if stream_alive[0] and stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ci_ct += 1\n",
    "            elif stream_alive[0] and not stream_alive[1] and stream_alive[2]:\n",
    "                pattern_ci_d += 1\n",
    "            elif not stream_alive[0] and stream_alive[1] and stream_alive[2]:\n",
    "                pattern_ct_d += 1\n",
    "        elif num_alive == 3:\n",
    "            exactly_3_alive += 1\n",
    "    \n",
    "    total_neurons = len(counts_all)\n",
    "    \n",
    "    print(f\"\\n{case_name.upper()} ({total_neurons} total neurons)\")\n",
    "    print(\"─\" * 50)\n",
    "    \n",
    "    # Overall Pattern Summary\n",
    "    print(\"OVERALL ACTIVATION PATTERNS:\")\n",
    "    print(f\"  All dead (0/3):          {exactly_0_alive:4d} ({exactly_0_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  All alive (3/3):         {exactly_3_alive:4d} ({exactly_3_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  Mixed (1/3):             {exactly_1_alive:4d} ({exactly_1_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  Mixed (2/3):             {exactly_2_alive:4d} ({exactly_2_alive/total_neurons*100:5.1f}%)\")\n",
    "    \n",
    "    # Stream-Specific Dead Counts\n",
    "    print(f\"\\nSTREAM-SPECIFIC DEAD COUNTS:\")\n",
    "    for i, (name, count) in enumerate(zip(stream_names, stream_dead_counts)):\n",
    "        pct = (count / total_neurons) * 100\n",
    "        print(f\"  {name:12}: {count:4d} dead ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Detailed Pattern Breakdowns\n",
    "    if exactly_1_alive > 0:\n",
    "        print(f\"\\n1/3 PATTERN BREAKDOWN:\")\n",
    "        print(f\"  CLIP-img only:           {pattern_ci_only:3d} ({pattern_ci_only/exactly_1_alive*100:5.1f}%)\")\n",
    "        print(f\"  CLIP-txt only:           {pattern_ct_only:3d} ({pattern_ct_only/exactly_1_alive*100:5.1f}%)\")\n",
    "        print(f\"  DINO only:               {pattern_d_only:3d} ({pattern_d_only/exactly_1_alive*100:5.1f}%)\")\n",
    "    \n",
    "    if exactly_2_alive > 0:\n",
    "        print(f\"\\n2/3 PATTERN BREAKDOWN:\")\n",
    "        print(f\"  CLIP-img + CLIP-txt:     {pattern_ci_ct:3d} ({pattern_ci_ct/exactly_2_alive*100:5.1f}%)\")\n",
    "        print(f\"  CLIP-img + DINO:         {pattern_ci_d:3d} ({pattern_ci_d/exactly_2_alive*100:5.1f}%)\")\n",
    "        print(f\"  CLIP-txt + DINO:         {pattern_ct_d:3d} ({pattern_ct_d/exactly_2_alive*100:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dbb2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALIGNMENT PATTERNS ANALYSIS\n",
      "Goal: Understand which specific stream combinations are active (1/3, 2/3, 3/3)\n",
      "============================================================\n",
      "\n",
      "global_cross (8192 total neurons):\n",
      "  All dead (0/3):          1280 ( 15.6%)\n",
      "  All alive (3/3):         6912 ( 84.4%)\n",
      "  Mixed (1/3):                0 (  0.0%)\n",
      "  Mixed (2/3):                0 (  0.0%)\n",
      "\n",
      "  1/3 Breakdown:\n",
      "\n",
      "  2/3 Breakdown:\n",
      "\n",
      "global_no_cross (8192 total neurons):\n",
      "  All dead (0/3):           131 (  1.6%)\n",
      "  All alive (3/3):         8044 ( 98.2%)\n",
      "  Mixed (1/3):                2 (  0.0%)\n",
      "  Mixed (2/3):               15 (  0.2%)\n",
      "\n",
      "  1/3 Breakdown:\n",
      "    CLIP-img only:           0 (  0.0%)\n",
      "    CLIP-txt only:           0 (  0.0%)\n",
      "    DINO only:               2 (100.0%)\n",
      "\n",
      "  2/3 Breakdown:\n",
      "    CLIP-img + CLIP-txt:     2 ( 13.3%)\n",
      "    CLIP-img + DINO:        11 ( 73.3%)\n",
      "    CLIP-txt + DINO:         2 ( 13.3%)\n",
      "\n",
      "local_cross (8192 total neurons):\n",
      "  All dead (0/3):             0 (  0.0%)\n",
      "  All alive (3/3):         3575 ( 43.6%)\n",
      "  Mixed (1/3):              622 (  7.6%)\n",
      "  Mixed (2/3):             3995 ( 48.8%)\n",
      "\n",
      "  1/3 Breakdown:\n",
      "    CLIP-img only:          25 (  4.0%)\n",
      "    CLIP-txt only:          67 ( 10.8%)\n",
      "    DINO only:             530 ( 85.2%)\n",
      "\n",
      "  2/3 Breakdown:\n",
      "    CLIP-img + CLIP-txt:   104 (  2.6%)\n",
      "    CLIP-img + DINO:       3133 ( 78.4%)\n",
      "    CLIP-txt + DINO:       758 ( 19.0%)\n",
      "\n",
      "local_no_cross (8192 total neurons):\n",
      "  All dead (0/3):             0 (  0.0%)\n",
      "  All alive (3/3):         7019 ( 85.7%)\n",
      "  Mixed (1/3):                2 (  0.0%)\n",
      "  Mixed (2/3):             1171 ( 14.3%)\n",
      "\n",
      "  1/3 Breakdown:\n",
      "    CLIP-img only:           0 (  0.0%)\n",
      "    CLIP-txt only:           0 (  0.0%)\n",
      "    DINO only:               2 (100.0%)\n",
      "\n",
      "  2/3 Breakdown:\n",
      "    CLIP-img + CLIP-txt:     0 (  0.0%)\n",
      "    CLIP-img + DINO:       1152 ( 98.4%)\n",
      "    CLIP-txt + DINO:        19 (  1.6%)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Partial Alignment Patterns  \n",
    "print(\"ALIGNMENT PATTERNS ANALYSIS\")\n",
    "print(\"Goal: Understand which specific stream combinations are active (1/3, 2/3, 3/3)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for case_name, data in precomputed_data.items():\n",
    "    counts_all = data['counts_all']\n",
    "    \n",
    "    # Count all patterns\n",
    "    exactly_1_alive = 0\n",
    "    exactly_2_alive = 0\n",
    "    exactly_3_alive = 0\n",
    "    exactly_0_alive = 0\n",
    "    \n",
    "    # 1-out-of-3 patterns\n",
    "    pattern_ci_only = 0   # Only CLIP-img alive\n",
    "    pattern_ct_only = 0   # Only CLIP-txt alive  \n",
    "    pattern_d_only = 0    # Only DINO alive\n",
    "    \n",
    "    # 2-out-of-3 patterns\n",
    "    pattern_ci_ct = 0     # CLIP-img + CLIP-txt alive, DINO dead\n",
    "    pattern_ci_d = 0      # CLIP-img + DINO alive, CLIP-txt dead  \n",
    "    pattern_ct_d = 0      # CLIP-txt + DINO alive, CLIP-img dead\n",
    "\n",
    "    for i in range(len(counts_all)):\n",
    "        stream_alive = (counts_all[i].sum(axis=1) > 0)\n",
    "        num_alive = stream_alive.sum()\n",
    "        \n",
    "        if num_alive == 0:\n",
    "            exactly_0_alive += 1\n",
    "        elif num_alive == 1:\n",
    "            exactly_1_alive += 1\n",
    "            if stream_alive[0] and not stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ci_only += 1\n",
    "            elif not stream_alive[0] and stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ct_only += 1\n",
    "            elif not stream_alive[0] and not stream_alive[1] and stream_alive[2]:\n",
    "                pattern_d_only += 1\n",
    "        elif num_alive == 2:\n",
    "            exactly_2_alive += 1\n",
    "            if stream_alive[0] and stream_alive[1] and not stream_alive[2]:\n",
    "                pattern_ci_ct += 1\n",
    "            elif stream_alive[0] and not stream_alive[1] and stream_alive[2]:\n",
    "                pattern_ci_d += 1\n",
    "            elif not stream_alive[0] and stream_alive[1] and stream_alive[2]:\n",
    "                pattern_ct_d += 1\n",
    "        elif num_alive == 3:\n",
    "            exactly_3_alive += 1\n",
    "    \n",
    "    total_neurons = len(counts_all)\n",
    "    print(f\"\\n{case_name} ({total_neurons} total neurons):\")\n",
    "    print(f\"  All dead (0/3):          {exactly_0_alive:4d} ({exactly_0_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  All alive (3/3):         {exactly_3_alive:4d} ({exactly_3_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  Mixed (1/3):             {exactly_1_alive:4d} ({exactly_1_alive/total_neurons*100:5.1f}%)\")\n",
    "    print(f\"  Mixed (2/3):             {exactly_2_alive:4d} ({exactly_2_alive/total_neurons*100:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  1/3 Breakdown:\")\n",
    "    if exactly_1_alive > 0:\n",
    "        print(f\"    CLIP-img only:         {pattern_ci_only:3d} ({pattern_ci_only/exactly_1_alive*100:5.1f}%)\")\n",
    "        print(f\"    CLIP-txt only:         {pattern_ct_only:3d} ({pattern_ct_only/exactly_1_alive*100:5.1f}%)\")\n",
    "        print(f\"    DINO only:             {pattern_d_only:3d} ({pattern_d_only/exactly_1_alive*100:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  2/3 Breakdown:\")\n",
    "    if exactly_2_alive > 0:\n",
    "        print(f\"    CLIP-img + CLIP-txt:   {pattern_ci_ct:3d} ({pattern_ci_ct/exactly_2_alive*100:5.1f}%)\")\n",
    "        print(f\"    CLIP-img + DINO:       {pattern_ci_d:3d} ({pattern_ci_d/exactly_2_alive*100:5.1f}%)\")\n",
    "        print(f\"    CLIP-txt + DINO:       {pattern_ct_d:3d} ({pattern_ct_d/exactly_2_alive*100:5.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparc",
   "language": "python",
   "name": "sparc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
